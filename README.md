# Awesome-Token-Pruning-and-Merging-for-Multimodal-Large-Language-Models

## Early work

- [An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models](https://arxiv.org/abs/2403.06764) ![](https://img.shields.io/badge/abs-2024.05-red)
- [AIM: Adaptive Inference of Multi-Modal LLMs via Token Merging and Pruning](https://arxiv.org/abs/2412.03248).![](https://img.shields.io/badge/ICCV-2025.06-red)
- [AIM: Let Any Multi-modal Large Language Models Embrace Efficient In-Context Learning](https://arxiv.org/abs/2406.07588).![](https://img.shields.io/badge/AAAI-2024.06-red)
- [Variation-aware Vision Token Dropping for Faster Large Vision-Language Models](https://arxiv.org/abs/2509.01552).![](https://img.shields.io/badge/abs-2025.09-red)
- [Filter, Correlate, Compress: Training-Free Token Reduction for MLLM Acceleration](https://arxiv.org/abs/2411.17686).![](https://img.shields.io/badge/abs-2025.05-red)
